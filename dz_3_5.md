Домашнее задание к занятию "3.5. Файловые системы"

1. Узнайте о sparse (разряженных) файлах.
Разрежённый файл (англ. sparse file) — файл, в котором последовательности нулевых байтов[1] заменены на информацию об этих 

последовательностях (список дыр).

2. Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?

Не могут, т.к. ссылаются на один и тот же inode.

vagrant@vagrant:~$ touch temp_f

vagrant@vagrant:~$ ln temp_f temp_f_l

vagrant@vagrant:~$ ls -l temp_f*

-rw-rw-r-- 2 vagrant vagrant 0 Nov 26 16:33 temp_f

-rw-rw-r-- 2 vagrant vagrant 0 Nov 26 16:33 temp_f_l

chmod 0777 temp_f

vagrant@vagrant:~$ ls -il temp_f*

131165 -rwxrwxrwx 2 vagrant vagrant 0 Nov 26 16:33 temp_f

131165 -rwxrwxrwx 2 vagrant vagrant 0 Nov 26 16:33 temp_f_l




3. Сделайте vagrant destroy на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

Vagrant.configure("2") do |config|
  config.vm.box = "bento/ubuntu-20.04"
  config.vm.provider :virtualbox do |vb|
    lvm_experiments_disk0_path = "/tmp/lvm_experiments_disk0.vmdk"
    lvm_experiments_disk1_path = "/tmp/lvm_experiments_disk1.vmdk"
    vb.customize ['createmedium', '--filename', lvm_experiments_disk0_path, '--size', 2560]
    vb.customize ['createmedium', '--filename', lvm_experiments_disk1_path, '--size', 2560]
    vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', 

lvm_experiments_disk0_path]
    vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 2, '--device', 0, '--type', 'hdd', '--medium', 

lvm_experiments_disk1_path]
  end
end

Данная конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2.5 Гб.

4. Используя fdisk, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.


root@vagrant:/home/vagrant# fdisk -l /dev/sdb

Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors

Disk model: VBOX HARDDISK

Units: sectors of 1 * 512 = 512 bytes

Sector size (logical/physical): 512 bytes / 512 bytes

I/O size (minimum/optimal): 512 bytes / 512 bytes

Disklabel type: dos

Disk identifier: 0x56280084


Device     Boot   Start     End Sectors  Size Id Type

/dev/sdb1          2048 4196351 4194304    2G 83 Linux

/dev/sdb2       4196352 5242879 1046528  511M  5 Extended






5. Используя sfdisk, перенесите данную таблицу разделов на второй диск.

root@vagrant:/home/vagrant# sfdisk --dump /dev/sdb >sdb-t.txt


root@vagrant:/home/vagrant# cat sdb-t.txt

label: dos

label-id: 0x56280084

device: /dev/sdb

unit: sectors



/dev/sdb1 : start=        2048, size=     4194304, type=83

/dev/sdb2 : start=     4196352, size=     1046528, type=5



root@vagrant:/home/vagrant# sfdisk /dev/sdc < sdb-t.txt

Device     Boot   Start     End Sectors  Size Id Type

/dev/sdc1          2048 4196351 4194304    2G 83 Linux

/dev/sdc2       4196352 5242879 1046528  511M  5 Extended




6. Соберите mdadm RAID1 на паре разделов 2 Гб.

mdadm --create --verbose /dev/md0 -l 1 -n 2 /dev/sd{b1,c1}


root@vagrant:/home/vagrant# lsblk

NAME                 MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT

sda                    8:0    0   64G  0 disk

├─sda1                 8:1    0  512M  0 part  /boot/efi

├─sda2                 8:2    0    1K  0 part

└─sda5                 8:5    0 63.5G  0 part

  ├─vgvagrant-root   253:0    0 62.6G  0 lvm   /

  └─vgvagrant-swap_1 253:1    0  980M  0 lvm   [SWAP]

sdb                    8:16   0  2.5G  0 disk

├─sdb1                 8:17   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdb2                 8:18   0    1K  0 part

sdc                    8:32   0  2.5G  0 disk

├─sdc1                 8:33   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdc2                 8:34   0    1K  0 part






7. Соберите mdadm RAID0 на второй паре маленьких разделов.




mdadm --create --verbose /dev/md1 -l 0 -n 2 /dev/sd{b2,c2}



root@vagrant:/home/vagrant# lsblk

NAME                 MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT

sda                    8:0    0   64G  0 disk

├─sda1                 8:1    0  512M  0 part  /boot/efi

├─sda2                 8:2    0    1K  0 part

└─sda5                 8:5    0 63.5G  0 part

  ├─vgvagrant-root   253:0    0 62.6G  0 lvm   /

  └─vgvagrant-swap_1 253:1    0  980M  0 lvm   [SWAP]

sdb                    8:16   0  2.5G  0 disk

├─sdb1                 8:17   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdb2                 8:18   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0

sdc                    8:32   0  2.5G  0 disk

├─sdc1                 8:33   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdc2                 8:34   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0








8. Создайте 2 независимых PV на получившихся md-устройствах.

pvcreate /dev/md0

pvcreate /dev/md1





9. Создайте общую volume-group на этих двух PV.


root@vagrant:/home/vagrant# vgcreate VG_0 /dev/md{0,1}


root@vagrant:/home/vagrant# pvscan

  PV /dev/sda5   VG vgvagrant       lvm2 [<63.50 GiB / 0    free]

  PV /dev/md0    VG VG_0            lvm2 [<2.00 GiB / <2.00 GiB free]

  PV /dev/md1    VG VG_0            lvm2 [1016.00 MiB / 1016.00 MiB free]


  Total: 3 [66.48 GiB] / in use: 3 [66.48 GiB] / in no VG: 0 [0   ]


10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.


root@vagrant:/home/vagrant# lvcreate -L 100M VG_0 /dev/md1

  Logical volume "lvol0" created.


11. Создайте mkfs.ext4 ФС на получившемся LV.

root@vagrant:/home/vagrant# mkfs.ext4 /dev/VG_0/lvol0

mke2fs 1.45.5 (07-Jan-2020)

Creating filesystem with 25600 4k blocks and 25600 inodes


Allocating group tables: done

Writing inode tables: done

Creating journal (1024 blocks): done

Writing superblocks and filesystem accounting information: done



12. Смонтируйте этот раздел в любую директорию, например, /tmp/new.

root@vagrant:/home/vagrant# mkdir /tmp/new

root@vagrant:/home/vagrant# mount /dev/VG_0/lvol0 /tmp/new



13. Поместите туда тестовый файл, например wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz.

root@vagrant:/home/vagrant# wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz 

root@vagrant:/home/vagrant# ls -l /tmp/new

total 22032

drwx------ 2 root root    16384 Nov 28 11:53 lost+found

-rw-r--r-- 1 root root 22540872 Nov 28 06:02 test.gz



14. Прикрепите вывод lsblk.

root@vagrant:/home/vagrant# lsblk

NAME                 MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT

sda                    8:0    0   64G  0 disk

├─sda1                 8:1    0  512M  0 part  /boot/efi

├─sda2                 8:2    0    1K  0 part

└─sda5                 8:5    0 63.5G  0 part

  ├─vgvagrant-root   253:0    0 62.6G  0 lvm   /

  └─vgvagrant-swap_1 253:1    0  980M  0 lvm   [SWAP]

sdb                    8:16   0  2.5G  0 disk

├─sdb1                 8:17   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdb2                 8:18   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0

    └─VG_0-lvol0     253:2    0  100M  0 lvm   /tmp/new

sdc                    8:32   0  2.5G  0 disk

├─sdc1                 8:33   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

└─sdc2                 8:34   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0

    └─VG_0-lvol0     253:2    0  100M  0 lvm   /tmp/new




15. Протестируйте целостность файла:

root@vagrant:~# gzip -t /tmp/new/test.gz

root@vagrant:~# echo $?

0


root@vagrant:/home/vagrant# gzip -t /tmp/new/test.gz && echo $?

0



16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.

root@vagrant:/home/vagrant# pvmove /dev/md1

  /dev/md1: Moved: 8.00%

  /dev/md1: Moved: 100.00%


root@vagrant:/home/vagrant# lsblk

NAME                 MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT

sda                    8:0    0   64G  0 disk

├─sda1                 8:1    0  512M  0 part  /boot/efi

├─sda2                 8:2    0    1K  0 part

└─sda5                 8:5    0 63.5G  0 part

  ├─vgvagrant-root   253:0    0 62.6G  0 lvm   /

  └─vgvagrant-swap_1 253:1    0  980M  0 lvm   [SWAP]

sdb                    8:16   0  2.5G  0 disk

├─sdb1                 8:17   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

│   └─VG_0-lvol0     253:2    0  100M  0 lvm   /tmp/new

└─sdb2                 8:18   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0

sdc                    8:32   0  2.5G  0 disk

├─sdc1                 8:33   0    2G  0 part

│ └─md0                9:0    0    2G  0 raid1

│   └─VG_0-lvol0     253:2    0  100M  0 lvm   /tmp/new

└─sdc2                 8:34   0  511M  0 part

  └─md1                9:1    0 1018M  0 raid0





17. Сделайте --fail на устройство в вашем RAID1 md.



root@vagrant:/home/vagrant# mdadm /dev/md0 --fail /dev/sdb1

mdadm: set /dev/sdb1 faulty in /dev/md0





18. Подтвердите выводом dmesg, что RAID1 работает в деградированном состоянии.



[ 7148.772955] md/raid1:md0: Disk failure on sdb1, disabling device.

               md/raid1:md0: Operation continuing on 1 devices.





19. Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен:



root@vagrant:~# gzip -t /tmp/new/test.gz

root@vagrant:~# echo $?

0



root@vagrant:/home/vagrant# gzip -t /tmp/new/test.gz && echo $?

0





20. Погасите тестовый хост, vagrant destroy.

vagrant destroy.

